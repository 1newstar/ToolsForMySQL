面试总结：

​	[持续更新地址](https://github.com/naughtyGitCat/ToolsForMySQL/blob/master/%E6%B1%82%E8%81%8C/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.md)

[TOC]

## 基本盘：

​		虽然之前有过维护MySQL，但实际专职MySQL只有半年

​		在原公司半年自己的成长与大环境相比，退步

​		没有接触过分库分表等进阶技术。

​		目标城市：杭州，南京，目标：初级>中级

## 面试难点：

### 	1.原公司的业务量，会仔细问到每个表的大小，若有意掺水，可以先计算好。

### 	2.慢查询思路

​		系统：

​			PMM监控系统

​			每周切割一次慢日志，pt-query-digest分析后，发送到DBA组邮箱

​		优化：

​			先看执行计划，观察是否用尽可能用到索引

​			同时要关注预计扫描的行数，以及是否产生了临时表，或则是否需要进行排序

#### 		show processlist中需要关注的项：

​			copy to tmp table，建议把alter table操作放到低峰期运行

​			Copying to tmp table ，拷贝数据到内存中的临时表，常见于group by操作，加索引

​			Copying to tmp table on disk，临时表结果集太大，需要转换成临时表，增大sort buffer和tmp_table_size

​			Creating sort index，当前的SELECT需要用到临时表进行order by，建议加索引

​			Creating tmp table，建议创建适当的索引，少用UNION,VIEW,SUBQUERY

​			Sending data，从硬盘读取数据发送给客户端，建议通过索引，或者加上Limit，减少需要扫描并发送给客户端的数量

​			Sorting Result：正在对结果进行排序，类似Creating sort index，但是是在表内，而不是在临时表中，建议加索引。

#### explain中需要关注的项：

##### 			select type：

​						primary ，主键查询

​						simply，无表连接和子查询

​						UNION，出现在UNION后面的子句

​						SUBQUERY，子查询的语句

##### 			type（MySQL在子查询中找到所需行的方式）：

​						all，全表扫描，遍历整个表

​						index，索引全扫描，遍历整个列

​						range，索引范围扫描，（range,between,><）

​						ref，使用非唯一索引，或者复合的唯一索引的前缀列进行扫描

​						eq_ref，使用唯一索引（多表连接中使用主键或者唯一性索引关联）

​						const/system，单表使用主键或者唯一性索引进行查询

​						NULL，查询常量或者不设计表中数据	

#### extra(附加信息)：

​					using index，使用覆盖索引的时候会出现

​					using where，全索引扫描或者全表扫描(type列为ALL或者 index), 又加上where条件

​					using index condition 新特性ICP，把过滤推到引擎层处理

#### 		SQL解析顺序

​			8 SELECT 9 DISTINCT *selected column*

​			1  FROM *left table*

​			3 *join type* JOIN *right table* 

​			2				ON  *join condition*

​			4 WHERE *where condition*

​			5 GROUP BY *group by list*

​			6 HAVING *having condition*

​			10 ORDER BY 11 LIMIT

#### 		SQL改写点

​			通常情况下，子查询的性能太差，建议改造成JOIN写法

​			多表连接时，关联字段类型尽量一致，并且都要有索引；同时把过滤后结果集较小的表作为驱动表；排序字段应为驱动表的索引列

​			类似分页功能的SQL，先用主键关联后，再返回结果集，效率会高很多

​			多用复合索引，少用单列索引

​			varchar不排序时，索引可以建成前缀索引

​	

### 	3.高负载下MySQL的排查思路

​		1.先确认系统本身有无问题，是不是确实从应用端发来了大量请求

​		2.查看活跃线程数，活跃线程数陡升表示可能redis或者memcache缓存集穿

​		3.看show processlist中有没有大SQL

​		4.explain show processlist中的ID

​		5.情况异常严重可以kill掉连接，或者禁用这个事务的对应的账号或者主机

​		一般可能是不合理的SQL，或者没有用到合适的索引

### 	4.docker/整个业务系统的纵向思考

​		docker:资源隔离。模板化，但是维护上可能更麻烦，且数据的安全性和性能更是个问题

### 	5.B+树，索引，隔离级别

#### 		InnoDB表的特点：

​			基于B+树的索引表

​			每个表都需要有一个聚集索引

​			所有行记录都存储在B+树的叶子节点

​			基于聚集索引的增删改查效率是最高的

​			如果我们定义了主键，则InnoDB会选择其作为聚集索引

​			如果没有显式定义主键，则InnoDB会选择第一个非空的唯一索引作为聚集索引

​			如果上面的也不满足，则InnoDB会选择内置的6字节的ROWID作为隐含的索引。

#### 		综上所述：

​			如果InnoDB表的数据写入顺序能和B+树节点顺序保持一致的话，这时候存取效率是最高的。

​			1.使用自增列做主键，这时候写入顺序是自增的，和B+树叶子节点分裂顺序一致

​			2.该表不指定自增列作主键，同时也没有可以选为主键的非空唯一索引，这时候InnoDB会选择内置的ROWID作为主键，写入顺序和ROWID增长顺序一致。

​			3.若一个InnoDB表没有显示主键，却有可以被指定为主键的非空唯一性索引，但可能不是递增关系时（如字符串，UUID，多字段联合索引的情况），那么该表的存取效率就可能会比较差

​			page的结构是B+树，page内部则是链表

#### 		索引：

​			主键索引，普通索引，普通索引通过存储主键列的值完成，本质上是组合索引。

​			单列索引，组合索引，组合索引的最左匹配原则

​			自适应哈希索引，InnoDB会自动根据访问的频率和模式来为某些页建立哈希索引，本质是针对B+树Search Path的优化，所有涉及到Search Path的操作，均可以被优化

#### 		隔离级别：

​			RU>RC>RR>Seriallize

​			RC>RR：通过MVCC和间隙锁完成可重复读，间隙锁加在普通索引的范围的两端

#### 		锁：

​			表锁，不使用索引时，超过表大小的30%时

​			行锁，通过给索引上的索引水加锁实现的，只有通过索引检索，才会使用行锁

​			

​						

### 	6.高可用

#### GTID

​	全局事务ID，根据GTID可以知道事务最初是在哪个实例上提交的，防止环回复制

​	方便复制的故障转移

#### 复制延迟

##### 原因：

​	从库硬件差距

​	从库单个SQL_THREAD回放

​	 从库不执行业务，导致IBP中没有真正的热数据，每次执行都会执行大几率磁盘读

##### 解决办法：

​	给从库提升硬件性能，增大change buffer

​	大事务拆分

​	在主库上开启组提交（5.7默认开启），在从库上开启并行复制

 		slave-parallel-type=LOGICAL_CLOCK
 		slave-parallel-workers=4（HDD）或8（SSD）
 		master_info_repository=TABLE 
 		relay_log_info_repository=TABLE
 		relay_log_recovery=ON 

​	从库执行relay log时，走的主键索引，删除从库的普通索引可以加快，但需慎重

##### 落后多少秒，秒是怎么算出来的

​	Seconds_Behind_Master = io_thread.timestamp - sql_thread.timestamp	

​	The value of Seconds_Behind_Master is based on the timestamps stored in events, which are
preserved through replication. This means that if a master M1 is itself a slave of M0, any event from
M1's binary log that originates from M0's binary log has M0's timestamp for that event. This enables
MySQL to replicate TIMESTAMP successfully. However, the problem for Seconds_Behind_Master
is that if M1 also receives direct updates from clients, the Seconds_Behind_Master value
randomly fluctuates because sometimes the last event from M1 originates from M0 and sometimes is
the result of a direct update on M1. 

##### 大事务卡住时：

​	show slave status查看从库SLAVE执行到的位置

​	`mysqlbinlog -v --base64-output=decode-rows --start-position=Exec_Master_Log_Pos Relay_Master_Log_File |more `

##### 死锁：

​	加索引或者DDL重放

#### 半同步复制

##### 	参数：repl_semi_sync_master_wait_point

##### 	选项：

​			after commit

​			主库在执行完commit后，才会等待从库的ACK消息，这个时候若主库failover，且从库由于不可抗的原因没有收到传过来的数据时，这个已经在主库上commit的事务会彻底丢失，无法被恢复。

​			after sync

​			主库在执行完，会等待从库ACK，然后进行commit，这个时候若主库failover,且从库由于不可抗的原因没有收到传过来的数据，这个事务由于没有被提交，防范了事务丢失。

#### 		MHA

##### 		MHA的架构

##### 		MHA的切换原理

##### 		MHA的VIP挂载与卸除

​		见我的博客 [【MySQL】【高可用】基于MHA架构的MySQL高可用故障自动切换架构](http://blog.51cto.com/l0vesql/2068659 )

[【MySQL】【高可用】从masterha_master_switch工具简单分析MHA的切换逻辑](http://blog.51cto.com/l0vesql/2060910 )



#### 		Keepalived

##### 		Keepalived判断MySQL存活的逻辑:

​		1.判断机器本身是否存在mysqld进程

​		2.根据配置的账号进行连接mysqld，是否能连上

##### 		如何判断脑裂？

​		在上面的逻辑的最后加上ping网关的逻辑，若网关也ping不通则是本身网络有问题，不抢断VIP

##### 		数据安全性？

​		半同步来确保，或者监控判断延时，总之相比MHA，少了补数据的操作。



## 	7.MGR PXC

​		mgr:galera+paxos

​		pxc:galera

​		galera：说出写集提交验证的机制

## 	8.重要参数

#### 		全局参数：

​					table_cache，每个线程可以打开表的数量

​					thread_cache_size，可以复用的缓存起来的线程数，对高并发有奇效

​					back_log，MySQL暂停回答新请求前，短时间多少个请求可以被存在栈中

​					InnoDB_open_files，MySQL可以同时打开的ibd文件数

​					InnoDB_additional_mem_pool_size，设置了InnoDB引擎来存放数据字典信息以及一些内部数据结构的内存空间大小。当一个MySQL实例中的数据库对象非常多的的时候，需要调整该大小确保所有的数据都能放在内存中以提高访问效率。

​					InnoDB buffer pool，内存的50-70%

​					InnoDB log file size，redo的大小，控制在一小时产生事务日志大小的容量内

​					InnoDB log buffer size，redo buffer的大小，8-16M

​					InnoDB max_dirty_page_pct，脏页比，超出后会触发脏页落盘操作，50%

​					InnoDB lock wait timeout，行锁等待时间，超出后会报错，若高并发，行锁等待严重，可减少此值

#### 		线程参数：

​					thread_stack，分配给单个线程的内存大小，512KB

​					sort buffer，分配给每个线程处理排序

​					read_buffer，读入缓冲区大小，顺序扫描时用到，频繁扫描需加大

​					read_rnd_buffer，二级索引非顺序扫描时的读入缓冲区大小

​					join_buffer，表连接的缓冲

​					tmp_table_size，每个线程创建临时表的最大大小，超过这个大小后，会转成磁盘临时表

​			注意：所有的线程级别的缓存加在一起x最大线程数+IBP<系统内存*90%





​		

## 	9.5.6与5.7的区别

​		提供了对JSON的支持

​		可以explain一个正在运行的SQL（explain show processlist）

​		***在线修改buffer pool的大小***

​		***Online DDL的支持（不完全，只支持重命名索引，或者增加varchar长度）***

​		临时表只在当前会话中可见，生命周期为当前连接

​		***支持多源、多线程复制***

​		***SQL MODE  :Only full group by*** 

## 	10.监控模板

​		个别公司会问有没有自定义zabbix的模板，别管。

​		原理是通过在监控脚本里面配置账号密码，每隔5S，查询一次全局参数，然后分割得出各个参数项。

## 	11.备份，mysqldump为什么要rr,savepoint的应用方式，xtrabackup的最后结束时间

​		rr:防止不可重复读，幻读，产生数据不一致，

​		savepoint:如果不执行rollback to savpoint sp，DDL操作会一直Hang住，执行该操作后，DDL操作可以继续执行了。总之，提高了DDL的并发性，不会阻塞在备份期间对以备份表的DDL操作

​		xtrabackup的备份文件实际时间为结束备份的时间

#### 		备份流程：

​			mysqldump:关闭实例上所有已经打开的表，

​						加全局读锁

​						设置线程的隔离级别为rr，防止幻读和不可重复读

​						开启一致性快照事务

​						获取复制信息

​						释放全局读锁

​						结合savepoint开始一个一个表的select * ，减少单个表的DDL等待时间

​						结束，断开连接，原事务会自动停止

​			xtrabackup：生成一个xtrabackup.log的文件捕获redo文件

​						拷贝InnoDB相关文件（表数据文件，ibdata1回滚空间）

​						全局读锁

​						拷贝InnoDB表结构文件frm,非事务表的全部文件

​						获取Bin log位置

​						释放全局读锁，停止xtrabackup.log

​						

​				

## 	12.InnoDB线程，drop表的引擎内部动作。

#### 		master thread

​		刷新redo日志缓冲到磁盘（包含了未提交的事务），合并change buffer并刷新脏页到磁盘，删除无用的undo页

​		产生一个检查点

#### 		IO thread

​			insert buffer thread1个

​			Log buffer thread 1个

​			read thread 8个

​			write thread 8个

#### 		Purge thread

​			回收已经使用的undo页，支持多个Purge thread

#### 		Page Cleaner Thread

​			MySQL5.6版本以上引入，将之前版本中脏页刷新的操作都放到单独的线程中完成，目的是为了减轻原Master thread的工作及对于用户查询线程的阻塞，进一步提升InnoDB的性能



#### drop表的操作：

​			2次锁定LRU list，分别进行清除自适应哈希索引和LRU和flush list。

## 	13.JSON格式的支持

​	5.7版本中增加了对JSON格式的支持，面试官问到是否有过尝试优化mysql中JSON的思路。

​	答：只是有了解过，插入过数据。

​		但是术业有专攻，JSON最好还是用MongoDB来存储。现阶段业界暂未出现MySQL替代MongoDB做存储的知名案例。等到成熟了再测试，现在进行测试，浪费学习的精力。

​		贵公司为什么会考虑放弃MongoDB？

## 	14.InnoDB如何判断是否热数据，热数据是否在InnoDB buffer pool中？

​		LRU List按照功能被划分为两部分：LRU_young与LRU_old，默认情况下，LRU_old为链表长度的3/8。	  页面读取时(get/read ahead)，首先链入LRU_old的头部。页面第一次访问时(read/write)，从LRU_old链表移动到LRU_young的头部(整个LRU链表头)

​		热数据，一秒一次，否则进入Lru淘汰链表



## 	15.InnoDB crash recovery

​	1.从redo log文件里面得到最后一次checkpoint发生的LSN

​	2.从这个点开始应用重做日志

​	3.进行undo，反做未提交的事务

​	4.若开启了Binlog，那么在恢复过程中判断哪些事务未提交时会利用binlog

​	5.若未开启Binlog，那么会拿redo log entry的LSN与这行日志对应被修改页的LSN进行比较，若页的LSN大于等于redo log entry，那么表示这个页是干净的，不需要被回滚掉

## 工作中遇到的问题（虚构）

### 1.误删除一张大表

#### 	恢复方法：

​			1.xtrabackup的备份拿出来，删除其他所有业务表，只剩下被误删除的一张表。apply-log

​			2.挂到主库下，start slave until到被删除的时间点

​			3.交换表空间

### 2.负载过高，报max_connection

#### 	描述：

​		秒杀环境下，大量连接进来，新的连接无法连接数据库。

#### 	处理：

​		1.不能切换到从库，从库IBP没有热数据，从库会无法连接的同时整个库卡死

​		2.使用socket方式接入，更改最大并发连接数。

​		3.告诉系统运维限制前端最大并发连接数。

### 3.误删ibdata1

#### 	描述：

​		测试环境不规范，测试人员误删了ibdata1文件，删除后及时通知到我

#### 	处理：

​		1.进入cli，上全局读锁

​		2.找到mysqld所在的进程号

​		3.按进程号到/proc/目录下将文件找回

​		4.拷贝回原来的位置，释放读锁

### 4.强制关机或者杀进程导致无法启动

#### 	描述：

​		启动时报错：`The log sequence numbers 842222557 and 842222557 in ibdata files do not match the log sequence number 856874471 in the ib_logfiles!`

#### 	处理：

​		1.是因为ibdata1中的double write文件丢失活损坏导致的checksum校验失败

​		2.double write负责保证脏页刷入的稳定性，无法打开double write buffer，导致无法启动

​		3.`innodb_force_recovery=(0-6)`每个级别尝试进入基于redo和undo的innodb crash recovery

​		

​		

​	

## 附：

​	面了很多家之后感觉，每个公司考察DBA的侧重点都不同，有些地方疏漏遗忘在所难免，回来笔记即可。

​	面试的时候，要问下对方的规模和组织情况，问有没有自动化运维平台，问下结果的截止日期。

​	心态稳住，因为个人品格上的缺陷，加上之前的遗留问题，在一段时间内陷入抑郁状态。多谢各位兄弟的帮助，建议大家多跑步，[多听些歌](http://t3.kugou.com/song.html?id=4hBvE42t5V2 "世界第一等")

​	你们问我到底有没有找到工作，当然是没有，准备回家刨地了





